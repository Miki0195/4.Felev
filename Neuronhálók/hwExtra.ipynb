{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrEDzldtFaCL"
      },
      "source": [
        "# Szorgalmi házi feladat (Haladó NumPy)\n",
        "\n",
        "A szorgalmi házi feladat keretében három feldatot kell megoldanod a NumPy könyvtár segítségével. A cél, hogy minél hatékonyabb megoldásokat adj a feladatokra.\n",
        "\n",
        "Az egyes feladatok alatt tesztek találhatók, melyek kisméretű példákon ellenőrzik a megoldás helyességét. A notebook végén, a \"Benchmark tesztek\" blokkban olyan további tesztek vannak, melyek a megoldások futásidejét mérik le nagyméretű példákon. Kérjük, hogy **ne változtasd meg a notebook struktúráját**, ne szedd több részre, illetve ne módosítsd a megírt részeket, csak a megoldásaidat írd be a megfelelő helyre, az `# Implement your solution BELOW` feliratok alá közvetlenül. A beadott házi feladatok gépi tanulás alapú plágiumellenőrzésen esnek át. Másolás gyanújának felmerülése esetén mind a másolat(ok), mind az azt/azokat ihlető eredeti megoldások visszautasíthatók.\n",
        "\n",
        "**!!! A feladatok megoldását, vagy az arra mutató linkeket bárhol közzétenni tilos !!!**\n",
        "\n",
        "**Kikötések:**\n",
        "\n",
        "- Kizárólag a NumPy könyvtár használható, illetve olyan modulok, melyek a sztenderd Python disztribúció részei. Kizárólag Python nyelven írt saját kód használható.\n",
        "\n",
        "**Megoldás és beküldés menete:**\n",
        "\n",
        "A közzétett, feladatokat tartalmazó Jupyter notebook a Google Drive-on keresztül lett megosztva, így a Google saját Jupyter notebook szerkesztője és futtatókörnyezete nyílik meg a linkre kattintáskor, a Google Colab. Ennek segítségével online szerkeszthető és futtatható a megosztott notebook. Mivel a notebook csak \"view\" jogosultságokkal van megosztva, a Google Colab az úgynevezett \"Playground\" módban nyitja azt meg, ahol bár szerkeszthető és futtatható a notebook, de a változtatások nem lesznek automatikusan mentve. A notebook maradandó hatásokkal járó szerkesztése az alábbi módokon lehetséges:\n",
        "- Ha online szeretnénk a notebookot szerkeszteni és futtatni a Google Colab segítségével, akkor le kell másolni azt a saját Drive tárhelyre (Google Colab file menü -> Save a copy to Drive), majd a másolatot kell megnyitni szerkesztésre.\n",
        "\n",
        "A kész megoldást tartalmazó notebookot (.ipynb) fájlként kell feltölteni a Canvas-ban, a házi feladat beadási felületén.\n",
        "**Kérjük a notebook szerkezetét nem módosítani és nem szétszedni külön feladatok szerint!**\n",
        "\n",
        "**Határidő:** 2024. május 21., kedd, 23:59.\n",
        "\n",
        "**Értékelés:**\n",
        "\n",
        "A feladatok megoldásáért egyenként 5-5 pont szerezhető, azaz összesen 15 pont a három feladatért. Az egyes feladatok megoldása abban az esetben ér 5 pontot, ha\n",
        "- A megoldás teljesen vektorizált, azaz egyáltalán nincs benne Python ciklus, rekurzió, vagy hasonló, nem hatékony konstrukció, ahol a Python interpreter nagyszámú utasítást hajt végre. Ide tartoznak a list/set/dict comprehension-ök, és a `map(), filter()` függvények is. Nem hatékony konstrukciók NumPy-ban a `np.vectorize, np.apply_along_axis, np.frompyfunc` függvények is (lásd NumPy útmutató, 5. fejezet legvége: \"Tetszőleges Python kód vektorizálása\").\n",
        "- Az adott feladathoz tartozó benchmark tesztek közül, legalább a \"Benchmark #1\" teszt sikeresen lefut, kevesebb, mint 10 másodperc alatt, a Google Colab futtatási környezetén (CPU mód).\n",
        "\n",
        "**Verseny:**\n",
        "\n",
        "A hallgatók által beadott megoldások egymással is összehasonlításra kerülnek, a benchmark futási idők szerint. A beadott megoldásokat feladatonként rangsoroljuk a futási idők alapján a #2 és #3 sorszámú benchmark teszteken, majd az egyes hallgatók esetén összegezzük a három feladatra kapott, összesen hat darab rangsor helyezést. **A három legalacsonyabb rangsor-helyezés összeget elérő hallgató jeles érdemjegyet kap a tárgyra, amennyiben a minimum feltételeket teljesíti** (elégséges vizsga és a ZH-kon 20-20 pont). Ha egy teszt nem fut le 30 másodpercen belül, az azon elért rangsor helyezés az arra a feladatra beadott megoldások számával lesz egyenlő. Ha elfogy a futtatókörnyezet által biztosított memória és emiatt a futtatókörnyezet leáll/újraindul, az egyenértékű azzal, hogy a teszt nem futott le időben."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXWcqGjdwKyd"
      },
      "source": [
        "## **A**: Buszparkolás\n",
        "\n",
        "_Egy budapesti utazási iroda informatikusaként tengeted mindennapjaidat. A szokásos weblap karbantartási feladatok helyett, ezúttal egyedi, sürgős kéréssel fordulnak hozzád. Az iroda megkeresést kapott: nagyszámú, az ország különböző szegleteiből származó turista látogatná meg a Nemzeti Múzeumot a nemzeti ünnep alkalmából. Turistabuszokkal érkeznének délelőtt, majd a nap végén azokkal is mennének haza, azonban gondot okoz ennyi busz elhelyezése egyidejűleg a belvárosban. A munkatársaid azzal az ötlettel álltak elő, hogy a Múzeum körút két oldalára, a járda mellé állítanák sorban a buszokat, így oldva meg a parkolást. Meg is tették az előkészületeket, hogy a parkolóhelyek szabadok legyenek aznapra. A nemzeti ünnep reggelén viszont kollégáid váratlan felfedezést tettek: az éjszaka folyamán, ismeretlen tettesek amerikai rendszámú roncsautókat parkoltak le, szétszórva a körút két oldalán, galibát okozva ezzel a szervezőknek és a látogatóknak - az autók elszállítására már nincs elegendő idő. Munkatársaid felmérték a helyzetet, rögzítették digitális formában is, hogy melyik parkolóhelyen áll autó és melyik üres. Jól tudják, hogy te remekül programozol és nem mész a múzeumba, így téged bíznak meg annak a kiszámításával, hogy mennyi busz fog tudni a roncsautók közt parkolni a körút két oldalán. Nagyon sürgős a feladat és mivel gyakran be-beragadnak a régi billentyűzeteden a gombok, tudod, hogy csak kevéssé verbózus nyelveken lenne esélyed időben megoldani a feladatot, így a NumPy-t választod._\n",
        "\n",
        "Implementáld a `n_of_bus_parking_spaces` nevű függvényt, mely paraméterként a `parking_map` nevű, `(2, n)` alakú boolean tömböt kapja meg, ahol `n` pozitív! A tömb két sora a Múzeum körút két oldalán található, autók méretére szabott parkolóhelyeket reprezentálja sorban. A tömbben ott találhatók igaz értékek, ahol autó áll és hamis értékek jelzik a szabad helyeket. Egy busz elhelyezéséhez három egymást követő szabad parkolóhelyre van szükség. A függvény egy egész számmal kell, hogy visszatérjen, mely megadja, hogy hány buszt lehet elhelyezni az útszakasz két oldalán összesen!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "q2DeifZm6PlJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# implement your solution BELOW\n",
        "def n_of_bus_parking_spaces(parking_map):\n",
        "    kernel = np.array([1, 1, 1])\n",
        "\n",
        "    parking_map_padded = np.pad(parking_map, ((0, 0), (1, 1)), constant_values=True)\n",
        "\n",
        "    conv_left = np.convolve(~parking_map_padded[0], kernel, mode='valid')\n",
        "    conv_right = np.convolve(~parking_map_padded[1], kernel, mode='valid')\n",
        "\n",
        "    buses_left = count_buses(conv_left)\n",
        "    buses_right = count_buses(conv_right)\n",
        "\n",
        "    return buses_left + buses_right\n",
        "\n",
        "def count_buses(conv):\n",
        "    bus_indices = np.where(conv == 3)[0]\n",
        "    bus_indices = bus_indices[::2]\n",
        "    return len(bus_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuUuXZfT_Bvd"
      },
      "source": [
        "### Tesztek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "i4HI-ZA5_Bve",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "583ee039-6339-409e-ed3d-0b1ece854708"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test1 (__main__.TestBusParking) ... ok\n",
            "test2 (__main__.TestBusParking) ... ok\n",
            "test3 (__main__.TestBusParking) ... ok\n",
            "test4 (__main__.TestBusParking) ... ok\n",
            "test5 (__main__.TestBusParking) ... ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 5 tests in 0.023s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.runner.TextTestResult run=5 errors=0 failures=0>"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ],
      "source": [
        "import unittest\n",
        "\n",
        "class TestBusParking(unittest.TestCase):\n",
        "    def test1(self):\n",
        "        parking_map = np.array([[0,0,1,0,0],\n",
        "                                [1,0,0,1,0]], dtype=np.bool_)\n",
        "        self.assertEqual(n_of_bus_parking_spaces(parking_map=parking_map), 0)\n",
        "\n",
        "    def test2(self):\n",
        "        parking_map = np.array([[0],\n",
        "                                [0]], dtype=np.bool_)\n",
        "        self.assertEqual(n_of_bus_parking_spaces(parking_map=parking_map), 0)\n",
        "\n",
        "    def test3(self):\n",
        "        parking_map = np.array([[1,0,0,0,1,0,0,0],\n",
        "                                [0,0,0,0,0,0,0,0]], dtype=np.bool_)\n",
        "        self.assertEqual(n_of_bus_parking_spaces(parking_map=parking_map), 4)\n",
        "\n",
        "    def test4(self):\n",
        "        parking_map = np.array([[1,0,1,1,1,0,1,1],\n",
        "                                [0,0,1,0,0,0,0,1]], dtype=np.bool_)\n",
        "        self.assertEqual(n_of_bus_parking_spaces(parking_map=parking_map), 1)\n",
        "\n",
        "    def test5(self):\n",
        "        parking_map = np.array([[0,0,0,1,0,0,1,0,1,0,0,0,0,0,1,1,0,0,0,0,1,0,0,0],\n",
        "                                [0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,1,0,0,0,1,0,1,0]], dtype=np.bool_)\n",
        "        self.assertEqual(n_of_bus_parking_spaces(parking_map=parking_map), 8)\n",
        "\n",
        "def suite():\n",
        "    suite = unittest.TestSuite()\n",
        "    testfuns = [\"test1\", \"test2\", \"test3\", \"test4\", \"test5\"]\n",
        "    [suite.addTest(TestBusParking(fun)) for fun in testfuns]\n",
        "    return suite\n",
        "\n",
        "runner = unittest.TextTestRunner(verbosity=2)\n",
        "runner.run(suite())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9qa9CVeTWm4"
      },
      "source": [
        "## **B**: Multi-class recall (szenzitivitás) metrika\n",
        "\n",
        "_Multi-class klasszifikáció esetén a mintaelemeink címkéjét k (k > 2) kategória egyikébe becsüljük (például kutya, macska, papagáj, stb.). Ha a becsléshez neuronhálót használunk (a végén egy softmax aktivációs függvénnyel), mintaelemenként egy-egy k elemű, valószínűségeket tartalmazó vektort kapunk, ahol az egyes valószínűségek a mintaelem egyes kategóriákba tartozásának valószínűségét reprezentálják. Ha szeretnénk ezekből a vektorokból megmondani, hogy egy-egy mintaelem melyik kategóriába tartozik a legnagyobb valószínűség szerint, akkor elég megmondani minden egyes vektorban a maximális elem indexét. Így megkapjuk a becsült kategóriákat._\n",
        "\n",
        "_Klasszifikációs modellek teljesítményének mérésére különböző metrikák léteznek (pl. pontosság - accuracy, precizitás - precision, szenzitivitás - recall, stb.). Az egyes metrikák a teljesítményt csak bizonyos szempontok szerint értékelik, jellemzően, egy modell egyetlen metrikával történő kiértékelése nem ad teljes képet a modell klasszifikációs teljesítményéről._\n",
        "\n",
        "Ebben a feladatban a **recall (szenzitivitás)** metrikát kell implementálnod a **multi-class** (kettőnél több kategóriás) **klasszifikáció esetére.** A multiclass recall, az összes kategória felett átlagolva, azt adja meg, hogy egy-egy választott kategóriába valójában tartozó egyedeket milyen arányban sikerült a megfelelő címkével ellátnunk.\n",
        "\n",
        "Számolásához a bináris (két kategóriás) esetből indulhatunk ki. Ilyenkor az egyik, választott kategóriánk a pozitív kategória, míg a másik a negatív kategória. A bináris recall metrika így a következő:\n",
        "\n",
        "$$ Recall = \\dfrac{VP}{VP+FN} $$\n",
        "\n",
        "ahol VP a valós pozitívok száma (azaz ahol a pozitív kategóriát helyesen becsültük), FN pedig a fals negatívok száma (ahol helytelenül a negatív kategóriába soroltuk a mintaelemet). A nevező tehát egyenlő azzal, hogy hány mintaelem tartozik a pozitív kategóriába, maga a hányados pedig azzal, hogy milyen arányban találtuk el a valójáan pozitív kategóriába tartozó elemeket.\n",
        "\n",
        "Multi-class esetben minden kategóriára számoljuk a fenti arányt úgy, hogy az aktuális kategória a pozitív kategória és mindegyik másik kategória együttvéve a negatív kategória. Az így, kategóriánként kapott recall értékeknek az átlaga adja meg a multi-class recall metrikát.\n",
        "\n",
        "A feladat, hogy implementáld a `multiclass_recall` függvényt, ami két paramétert kap:\n",
        "*   `y_pred` tartalmazza becsült valószínűségeket (ez egy (m, k) alakú, `np.float32` adattípusú tömb, ahol  m  a mintaelemek és  k  a kategóriák száma, m >= 1, k >= 3)\n",
        "*   `y_true` tartalmazza az igazi kategóriacímkéket (ez egy (m,) alakú, `np.int32` adattípusú tömb)\n",
        "\n",
        "A függvény egy lebegőpontos számot ad vissza, a kategóriákra egyenként számolt bináris recall értékek átlagát.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "aABdaC47WgPO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# implement your solution BELOW\n",
        "\n",
        "def multiclass_recall(y_pred, y_true):\n",
        "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "    k = y_pred.shape[1]\n",
        "    range_k = np.arange(k)\n",
        "\n",
        "    y_true_broadcasted = y_true[:, None] == range_k\n",
        "    y_pred_labels_broadcasted = y_pred_labels[:, None] == range_k\n",
        "\n",
        "    true_positives = np.sum(y_true_broadcasted & y_pred_labels_broadcasted, axis=0)\n",
        "    false_negatives = np.sum(y_true_broadcasted & ~y_pred_labels_broadcasted, axis=0)\n",
        "\n",
        "    recalls = np.divide(true_positives, true_positives + false_negatives, out=np.zeros_like(true_positives, dtype=float), where=(true_positives + false_negatives)!=0)\n",
        "\n",
        "    average_recall = np.mean(recalls)\n",
        "\n",
        "    return average_recall\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bfz8_900dlD1"
      },
      "source": [
        "### Tesztek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "6B0-d3bddois",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "587b3051-389f-4d90-9d4e-06dfd9d62bfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test_three_classes1 (__main__.TestMulticlassRecall) ... ok\n",
            "test_three_classes2 (__main__.TestMulticlassRecall) ... ok\n",
            "test_four_classes (__main__.TestMulticlassRecall) ... ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 3 tests in 0.018s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.runner.TextTestResult run=3 errors=0 failures=0>"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ],
      "source": [
        "import unittest\n",
        "\n",
        "class TestMulticlassRecall(unittest.TestCase):\n",
        "\n",
        "    def test_three_classes1(self):\n",
        "        three_class_preds = np.array([[0.4, 0.3, 0.3], [0.1, 0.5, 0.4],\n",
        "                                    [0.3, 0.2, 0.5], [0.4, 0.25, 0.35]], dtype=np.float32)\n",
        "        three_class_labels = np.array([2, 1, 0, 1], dtype=np.int32)\n",
        "        self.assertAlmostEqual(multiclass_recall(y_pred=three_class_preds, y_true=three_class_labels), 1/6)\n",
        "\n",
        "    def test_three_classes2(self):\n",
        "        three_class_preds = np.array([[0.1, 0.8, 0.1], [0.1, 0.5, 0.4],\n",
        "                                    [0.7, 0.2, 0.1], [0.25, 0.4, 0.35]], dtype=np.float32)\n",
        "        three_class_labels = np.array([1, 1, 1, 0], dtype=np.int32)\n",
        "        self.assertAlmostEqual(multiclass_recall(y_pred=three_class_preds, y_true=three_class_labels), 2/9)\n",
        "\n",
        "    def test_four_classes(self):\n",
        "        four_class_preds = np.array([[1., 0., 0., 0.], [1., 0., 0., 0.],\n",
        "                                     [0., 0., 1., 0.], [0., 0., 1., 0.],\n",
        "                                     [0., 1., 0., 0.], [0., 0., 0., 1.],\n",
        "                                     ], dtype=np.float32)  # [0,0,2,2,1,3]\n",
        "        four_class_labels = np.array([0, 2, 1, 1, 1, 3], dtype=np.int32)\n",
        "        self.assertAlmostEqual(multiclass_recall(y_pred=four_class_preds, y_true=four_class_labels), 7/12)\n",
        "\n",
        "def suite():\n",
        "    suite = unittest.TestSuite()\n",
        "    testfuns = [\"test_three_classes1\", \"test_three_classes2\", \"test_four_classes\"]\n",
        "    [suite.addTest(TestMulticlassRecall(fun)) for fun in testfuns]\n",
        "    return suite\n",
        "\n",
        "runner = unittest.TextTestRunner(verbosity=2)\n",
        "runner.run(suite())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OS5196bgCOwF"
      },
      "source": [
        "## **C**: Bounding box-ok\n",
        "\n",
        "_A számítógépes látás egyik fontos alkalmazása objektumok felismerése és elhelyezkedésük meghatározása fényképeken. A gépi tanulás alapú objektum-detektorokat nagyrészt felügyelt tanulás keretében tanítják be, fénykép-címke párokon. A címkék ebben az esetben, gyakran téglalapok adatai szoktak lenni. Ezek a téglalapok (más néven \"bounding box\"-ok), a fényképeken elhelyezve megadják, hogy egy adott objektum hol található meg a képen és mekkora a kiterjedése. A téglalapok oldalai párhuzamosak a kép oldalaival. Például, ha egy fényképen öt kutya található és ezúttal kizárólag a kutyák felismerésével szeretnénk foglalkozni, akkor az ehhez a képhez kapcsolódó címke öt téglalap méretét és elhelyezkedését adja meg, melyek az öt kutyát egyenként, a teljes terjedelmükben, a lehető legszorosabban magukban foglalják. Az objektum-detektor célja, hogy ezeket a téglalapokat minél kisebb hibával megbecsülje. Az igazi és becsült téglalpok közti hiba mérésére több fajta módszer létezik. A becslés módjától függően felmerülhet olyan kérdés is, hogy hogyan kezeljünk olyan eseteket, amikor az igazi téglalapok száma és a becsült téglalapok száma nem azonos. Ebben a feladatban egy ilyen metrikához felhasználható segédfüggvényt kell megvalósítani, mely minden igazi téglalapra megadja a hozzá a becsült téglalapok közül a legjobban illeszkedőt az Intersection-over-Union (IoU) metrikát követve._\n",
        "\n",
        "Definiáld a `best_matching_bboxes(bboxes_true, bboxes_pred)` függvényt! `bboxes_true` és `bboxes_pred` két NumPy tömb, `(n, 4)` és `(m, 4)` alakkal, ahol `n` az igazi téglalapok száma, `m` pedig a becsült téglalapok száma. Az egyes téglalapok négy darab egész számmal vannak ábrázolva, ezek sorban: a téglalap tetejének függőleges koordinátája, a téglalap bal oldalának vízszintes koordinátája, a téglalap aljának függőleges koordinátája és a téglalap jobb oldalának vízszintes koordinátája lesznek (\"tlbr\" formátum: top-left-bottom-right). A függvény egy `(n,)` alakú tömbbel tér vissza, melyben minden igazi téglalaphoz (tehát a `bboxes_true` tömb minden sorához) megadja annak a téglalapnak az indexét a `bboxes_pred` tömbből, amelyikkel annak a legnagyobb az átfedési aránya az IoU metrika szerint. Ha holtversenyben több ilyen téglalap van, az egyik tetszőleges téglalapot tekinti a maximális átfedési arányúak közül. Amennyiben egy igazi téglalappal egyetlen becsült téglalapnak sincs pozitív területű metszete (azaz az IoU érték 0), úgy a visszaadott tömb megfelelő helyén `-1` értéket kell visszaadni.\n",
        "\n",
        "$A$ és $B$ téglalapok átfedési aránya az IoU metrika szerint mérve a következő:\n",
        "\n",
        "$\\displaystyle \\qquad\\mathrm{IoU}(A, B) = \\frac{A \\cap B}{A \\cup B}$\n",
        "\n",
        "azaz, a két téglalap egymást átfedő területének és a két téglalap által együttesen lefedett területnek az aránya.\n",
        "\n",
        "Feltételezhetjük, hogy mindkét tömbben a számnégyesek pozitív területű téglalapokat határoznak meg. Feltételezhetjük továbbá, hogy az igazi téglalapok száma (`n`) nagyobb, mint nulla, azonban a becsült téglalapok száma (`m`) lehet nulla is. A téglalapokat meghatározó értékek egész számok, a bemeneti tömbök adattípusa `np.int32`.\n",
        "\n",
        "**Vizuális példa:**\n",
        "\n",
        "Az alábbi ábrán a világoskék téglalapok az igazi bounding box-ok, a narancssárgák pedig a becsült bounding box-ok. Az indexeik az input tömbökben a téglalapok alatt/felett vannak jelölve. Ezekre az inputokra a `best_matching_bboxes` függvény az `[1, -1]` tömböt adja vissza.\n",
        "\n",
        "<br>\n",
        "<img src=\"https://docs.google.com/uc?export=download&id=1zC7DgaE-a3IKnZJZ3HiUhlA4nVAnA9r-\" style=\"display:inline-block\" width='40%'>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "o8jE3pCwCRT-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# implement your solution BELOW\n",
        "def best_matching_bboxes(bboxes_true, bboxes_pred):\n",
        "    if bboxes_pred.size == 0:\n",
        "        return np.full(bboxes_true.shape[0], -1, dtype=np.int32)\n",
        "\n",
        "    box1_area = (bboxes_true[:, 2] - bboxes_true[:, 0]) * (bboxes_true[:, 3] - bboxes_true[:, 1])\n",
        "    box2_area = (bboxes_pred[:, 2] - bboxes_pred[:, 0]) * (bboxes_pred[:, 3] - bboxes_pred[:, 1])\n",
        "\n",
        "    intersect_top = np.maximum(bboxes_true[:, None, 0], bboxes_pred[:, 0])\n",
        "    intersect_left = np.maximum(bboxes_true[:, None, 1], bboxes_pred[:, 1])\n",
        "    intersect_bottom = np.minimum(bboxes_true[:, None, 2], bboxes_pred[:, 2])\n",
        "    intersect_right = np.minimum(bboxes_true[:, None, 3], bboxes_pred[:, 3])\n",
        "\n",
        "    intersect_area = np.maximum(0, intersect_bottom - intersect_top) * np.maximum(0, intersect_right - intersect_left)\n",
        "\n",
        "    union_area = box1_area[:, None] + box2_area - intersect_area\n",
        "\n",
        "    iou = np.divide(intersect_area, union_area, out=np.zeros_like(intersect_area, dtype=float), where=union_area!=0)\n",
        "\n",
        "    best_matches = np.argmax(iou, axis=1)\n",
        "    best_matches[iou.max(axis=1) == 0] = -1\n",
        "\n",
        "    return best_matches\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI8WBLu5CVDf"
      },
      "source": [
        "### Tesztek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "E23SKiWGCVDg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d87c8718-5c3c-42ad-9987-19cab528f8d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test1 (__main__.TestBestMatchingBBoxes) ... ok\n",
            "test2 (__main__.TestBestMatchingBBoxes) ... ok\n",
            "test3 (__main__.TestBestMatchingBBoxes) ... ok\n",
            "test4 (__main__.TestBestMatchingBBoxes) ... ok\n",
            "test5 (__main__.TestBestMatchingBBoxes) ... ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 5 tests in 0.020s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.runner.TextTestResult run=5 errors=0 failures=0>"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ],
      "source": [
        "import unittest\n",
        "\n",
        "class TestBestMatchingBBoxes(unittest.TestCase):\n",
        "    def test1(self):\n",
        "        bboxes_true = np.array([[-4, 7, -2, 13], [-3, 8, 5, 11]], dtype=np.int32)\n",
        "        bboxes_pred = np.zeros((0, 4), dtype=np.int32)\n",
        "        ret = best_matching_bboxes(bboxes_true=bboxes_true, bboxes_pred=bboxes_pred)\n",
        "        self.assertEqual(ret.tolist(), [-1, -1])\n",
        "\n",
        "    def test2(self):\n",
        "        bboxes_true = np.array([[-4, 7, -2, 13], [-3, 8, 5, 11], [7, 0, 12, 1]], dtype=np.int32)\n",
        "        bboxes_pred = np.array([[-3, 8, -2, 11], [-4, 8, -2, 11], [-2, 8, 4, 12], [6, -1, 12, 0]], dtype=np.int32)\n",
        "        ret = best_matching_bboxes(bboxes_true=bboxes_true, bboxes_pred=bboxes_pred)\n",
        "        self.assertEqual(ret.tolist(), [1, 2, -1])\n",
        "\n",
        "    def test3(self):\n",
        "        bboxes_true = np.array([[1, 1, 2, 2], [2, 2, 3, 3]], dtype=np.int32)\n",
        "        bboxes_pred = np.array([[1, 2, 2, 3], [2, 1, 3, 2]], dtype=np.int32)\n",
        "        ret = best_matching_bboxes(bboxes_true=bboxes_true, bboxes_pred=bboxes_pred)\n",
        "        self.assertEqual(ret.tolist(), [-1, -1])\n",
        "\n",
        "    def test4(self):\n",
        "        bboxes_true = np.array([[-3, -13, 0, -10], [-2, -12, 1, -9]], dtype=np.int32)\n",
        "        bboxes_pred = np.array([[-2, -12, 0, -10], [-3, -13, -1, -11], [-2, -12, 1, -9]], dtype=np.int32)\n",
        "        ret_ls = best_matching_bboxes(bboxes_true=bboxes_true, bboxes_pred=bboxes_pred).tolist()\n",
        "        self.assertIn(ret_ls[0], {0, 1})\n",
        "        self.assertEqual(ret_ls[1], 2)\n",
        "\n",
        "    def test5(self):\n",
        "        bboxes_true = np.array([[-3, -13, 0, -10], [-2, -12, 1, -9]], dtype=np.int32)\n",
        "        bboxes_pred = np.array([[-2, -12, 1, -9], [-3, -13, 0, -10], [-2, -12, 1, -9], [-3, -13, 0, -10]], dtype=np.int32)\n",
        "        ret_ls = best_matching_bboxes(bboxes_true=bboxes_true, bboxes_pred=bboxes_pred).tolist()\n",
        "        self.assertIn(ret_ls[0], {1, 3})\n",
        "        self.assertIn(ret_ls[1], {0, 2})\n",
        "\n",
        "def suite():\n",
        "    suite = unittest.TestSuite()\n",
        "    testfuns = [\"test1\", \"test2\", \"test3\", \"test4\", \"test5\"]\n",
        "    [suite.addTest(TestBestMatchingBBoxes(fun)) for fun in testfuns]\n",
        "    return suite\n",
        "\n",
        "runner = unittest.TextTestRunner(verbosity=2)\n",
        "runner.run(suite())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79IF4fT9ifYa"
      },
      "source": [
        "## Benchmark tesztek\n",
        "\n",
        "A NumPy megoldásaid futási idejét az alábbi kódblokk méri le. A kód különböző hardvereken futhat (a Colab futtatókörnyezethez is különböző processzorok társulhatnak), ezért különböző futtatási környezetekben mért futási idők nem hasonlíthatók össze."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "4nd3wl8BjUtA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "919f9db1-8de5-4c28-a673-4629dce58cbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running benchmarks...\n",
            "    task_A, Benchmark #0 (warmup): 0.002065420150756836 seconds. \n",
            "    task_A, Benchmark #1: 0.26412153244018555 seconds. \n",
            "    task_A, Benchmark #2: 6.464077949523926 seconds. \n",
            "    task_A, Benchmark #3: 2.0035135746002197 seconds. \n",
            "    task_B, Benchmark #0 (warmup): 0.026187419891357422 seconds. \n",
            "    task_B, Benchmark #1: 0.6212987899780273 seconds. \n",
            "    task_B, Benchmark #2: 11.547792434692383 seconds. \n",
            "    task_B, Benchmark #3: 2.0553221702575684 seconds. \n",
            "    task_C, Benchmark #0 (warmup): 0.016889572143554688 seconds. \n",
            "    task_C, Benchmark #1: 0.3587002754211426 seconds. \n",
            "    task_C, Benchmark #2: 2.706800937652588 seconds. \n",
            "    task_C, Benchmark #3: 3.368978977203369 seconds. \n"
          ]
        }
      ],
      "source": [
        "# Random test argument generation functions for the three exercises\n",
        "\n",
        "def gen_benchmark_args_A(size1, p_car):\n",
        "  # -> (2, n) bool_\n",
        "  assert 1 <= size1\n",
        "  assert 0. <= p_car <= 1.\n",
        "  return np.random.rand(2, size1) < p_car\n",
        "\n",
        "def gen_benchmark_args_B(n_samples, n_cat, accuracy):\n",
        "  # -> (n_samples, n_cat) fl32, (n_samples,) i32\n",
        "  assert 1 <= n_samples\n",
        "  assert 3 <= n_cat\n",
        "  y_true = np.random.randint(n_cat, size=(n_samples,), dtype=np.int32)   # (n_samples,)\n",
        "  y_pred_cat = y_true.copy()\n",
        "  miscat_mask = np.random.rand(n_samples) >= accuracy                    # (n_samples,) bool_\n",
        "  y_pred_miscat = np.random.randint(n_cat-1, size=np.count_nonzero(miscat_mask))\n",
        "\n",
        "  # make sure miscategorized samples do not get the correct label to ensure specified accuracy\n",
        "  y_pred_miscat = np.where(y_pred_miscat < y_true[miscat_mask], y_pred_miscat, y_pred_miscat+1)\n",
        "  y_pred_cat[miscat_mask] = y_pred_miscat\n",
        "  y_pred = np.full((n_samples, n_cat), dtype=np.float32, fill_value=-1.)                # (n_samples, n_cat)\n",
        "  y_pred[np.arange(n_samples), y_pred_cat] = 1\n",
        "\n",
        "  # randomly scale logits and apply softmax to get various probability values\n",
        "  y_pred *= np.fabs(np.random.normal(scale=5., size=(n_samples, 1)))  # scale logits within a sample uniformly\n",
        "  y_pred_exp = np.exp(y_pred)\n",
        "  y_pred = y_pred_exp / np.sum(y_pred_exp, axis=1, keepdims=True) + 1e-10\n",
        "\n",
        "  return y_pred, y_true\n",
        "\n",
        "def gen_benchmark_args_C(n_true_bboxes, n_pred_bboxes, tl_range, size_range):\n",
        "  # -> (n_true_bboxes, 4), (n_pred_bboxes, 4)\n",
        "  assert n_true_bboxes >= 1\n",
        "  assert n_pred_bboxes >= 0\n",
        "  assert tl_range >= 1\n",
        "  assert size_range >= 1\n",
        "  true_tl = np.random.randint(tl_range+1, size=(n_true_bboxes, 2)) - tl_range // 2\n",
        "  pred_tl = np.random.randint(tl_range+1, size=(n_pred_bboxes, 2)) - tl_range // 2\n",
        "  true_size = np.random.randint(size_range, size=(n_true_bboxes, 2))+1\n",
        "  pred_size = np.random.randint(size_range, size=(n_pred_bboxes, 2))+1\n",
        "  bboxes_true = np.concatenate([true_tl, true_tl+true_size], axis=1)\n",
        "  bboxes_pred = np.concatenate([pred_tl, pred_tl+pred_size], axis=1)\n",
        "  return bboxes_true, bboxes_pred\n",
        "\n",
        "# defining benchmarks test cases\n",
        "#    smaller \"warmup\" benchmarks are used to avoid including the time taken to load numpy functions for the first time in main benchmarks\n",
        "\n",
        "benchmarks = [\n",
        "              ('task_A, Benchmark #0 (warmup)', n_of_bus_parking_spaces, gen_benchmark_args_A, {'size1': 100000, 'p_car': 0.5}),\n",
        "              ('task_A, Benchmark #1', n_of_bus_parking_spaces, gen_benchmark_args_A, {'size1': 10000000, 'p_car': 0.5}),\n",
        "              ('task_A, Benchmark #2', n_of_bus_parking_spaces, gen_benchmark_args_A, {'size1': 200000000, 'p_car': 0.01}),\n",
        "              ('task_A, Benchmark #3', n_of_bus_parking_spaces, gen_benchmark_args_A, {'size1': 50000000, 'p_car': 0.5}),\n",
        "              ('task_B, Benchmark #0 (warmup)', multiclass_recall, gen_benchmark_args_B, {'n_samples': 100000, 'n_cat': 10, 'accuracy': 0.5}),\n",
        "              ('task_B, Benchmark #1', multiclass_recall, gen_benchmark_args_B, {'n_samples': 1000000, 'n_cat': 50, 'accuracy': 0.4}),\n",
        "              ('task_B, Benchmark #2', multiclass_recall, gen_benchmark_args_B, {'n_samples': 100000000, 'n_cat': 3, 'accuracy': 0.8}),\n",
        "              ('task_B, Benchmark #3', multiclass_recall, gen_benchmark_args_B, {'n_samples': 300000, 'n_cat': 1000, 'accuracy': 0.2}),\n",
        "              ('task_C, Benchmark #0 (warmup)', best_matching_bboxes, gen_benchmark_args_C, {'n_true_bboxes': 1000, 'n_pred_bboxes': 500, 'tl_range': 100, 'size_range': 10}),\n",
        "              ('task_C, Benchmark #1', best_matching_bboxes, gen_benchmark_args_C, {'n_true_bboxes': 3000, 'n_pred_bboxes': 2000, 'tl_range': 300, 'size_range': 10}),\n",
        "              ('task_C, Benchmark #2', best_matching_bboxes, gen_benchmark_args_C, {'n_true_bboxes': 5000, 'n_pred_bboxes': 10000, 'tl_range': 100, 'size_range': 10}),\n",
        "              ('task_C, Benchmark #3', best_matching_bboxes, gen_benchmark_args_C, {'n_true_bboxes': 10000, 'n_pred_bboxes': 5000, 'tl_range': 10000, 'size_range': 30})\n",
        "              ]  # list of (name - str, target_fn: Callable, gen_fn: Callable, gen_kwargs: dict)\n",
        "\n",
        "# run benchmarks test cases\n",
        "\n",
        "import time\n",
        "np.random.seed(0)\n",
        "\n",
        "print(\"Running benchmarks...\")\n",
        "for benchmark_item_tup in benchmarks:\n",
        "  benchmark_name, target_fn, gen_fn, gen_kwargs = benchmark_item_tup\n",
        "  benchmark_args = gen_fn(**gen_kwargs)\n",
        "  benchmark_args = benchmark_args if type(benchmark_args) is tuple else (benchmark_args,)\n",
        "  t0, t1 = None, None\n",
        "  try:\n",
        "    t0 = time.time()\n",
        "    ret = target_fn(*benchmark_args)\n",
        "    t1 = time.time()\n",
        "    del ret, benchmark_args\n",
        "  except:\n",
        "    pass   # uncomment except clause to see error in case a benchmark failed.\n",
        "  finally:\n",
        "    t_delta_str = f\"<failed>\" if (t0 is None) or (t1 is None) else f\"{t1-t0} seconds\"\n",
        "    print(f\"    {benchmark_name}: {t_delta_str}. \")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}